{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e227fcf-9618-404e-9a55-ed97bff4d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from env.cartpole import CartPole\n",
    "from env.system import ControlSystem, Controller, LinearQuadraticRegulator\n",
    "from base.construct import Construct\n",
    "from base.utilities import *\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "torch.set_flush_denormal(True)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c513559-81e7-4c36-9a31-f18c7e7a1551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ControlSystem(\n",
       "  (controller): Controller(\n",
       "    (fcl): ModuleList(\n",
       "      (0): Linear(in_features=4, out_features=1, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (loss_fn): TrajectoryLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device (cpu or cuda) and the control system object.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Send the control system object to device.\n",
    "cs = ControlSystem()\n",
    "cs.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2557e2-b8a8-4b54-9d10-3404ead2b52c",
   "metadata": {},
   "source": [
    "## Data generation and preparation\n",
    "\n",
    "The cell below generates and prepares the data to be sent to the training routine.  \n",
    "There is no need to change this cell. However, if you want, you can play with \n",
    "the batch_size and the total number of data points to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bcce3b8-b4d2-466a-bec3-b8a846372090",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(17)\n",
    "\n",
    "batch_size = 4\n",
    "total_size = batch_size * 60\n",
    "\n",
    "x_train_tensor = torch.empty((0,cs.robot.num_states))\n",
    "x_val_tensor = torch.empty((0,cs.robot.num_states))\n",
    "for _ in range(total_size):\n",
    "    x_train_tensor = torch.cat((x_train_tensor,\n",
    "                    torch.reshape(cs.robot.random_state(), \n",
    "                                  (1,cs.robot.num_states))), dim=0)\n",
    "    x_val_tensor = torch.cat((x_val_tensor,\n",
    "                    torch.reshape(cs.robot.random_state(), \n",
    "                                  (1,cs.robot.num_states))), dim=0)\n",
    "y_train_tensor = torch.zeros((len(x_train_tensor), 1))\n",
    "y_val_tensor = torch.zeros((len(x_val_tensor), 1))\n",
    "\n",
    "# Build data set containing all data zpoints\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "# Build a loader of each set\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd8142-1895-4e05-a548-c6b8e2ee0de8",
   "metadata": {},
   "source": [
    "## Create the loss function and the optimizer\n",
    "\n",
    "The cell below defines the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a972938-5e4e-4155-952b-675b32ab78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss() # define an L1 loss function.\n",
    "\n",
    "optimizer = optim.Adam(cs.parameters(), lr=0.0001)  # set the learning rate (gradient descent step size) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2888bf9-4aa3-49cb-ab09-e4517e132438",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of trainable parameters: {count_parameters(cs)}\")\n",
    "for name, layer in cs.named_modules():\n",
    "    print(name)\n",
    "cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a6e2d-d5dc-430f-bb8b-1da3b34c3a89",
   "metadata": {},
   "source": [
    "## Test the performance of the initial neural net vs linear quadratic regulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2c17a-7276-4e1c-a1a8-a0f769409326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear quadratic regulator and print its gains.  \n",
    "# Simulate 30 trajectories starting from the same initial condition (selected randomly)\n",
    "# with the neural net controller and the linear quadratic regulator.\n",
    "# Compute the performance of each controller and print the average performance ratio\n",
    "# defined as neural net performance / lqr performance.\n",
    "\n",
    "c = LinearQuadraticRegulator(device=device) # define lqr\n",
    "\n",
    "print(f\"LQR gains: {c.K}\")\n",
    "perf_ratio = 0\n",
    "for k in range(30):\n",
    "    torch.manual_seed(50)\n",
    "    s0 = cs.robot.random_state()\n",
    "    traj_learned, ctrl_learned = cs.robot.simulate(controller=cs.controller, s0=s0)\n",
    "    traj_lqr, ctrl_lqr = cs.robot.simulate(controller=c, s0=s0)\n",
    "    cur_ratio = cs.loss_fn(traj_learned, ctrl_learned).item()/cs.loss_fn(traj_lqr, ctrl_lqr).item()\n",
    "    perf_ratio = perf_ratio + cur_ratio \n",
    "print(\"--- Before training ---\")\n",
    "print(f\"Performance ratio: {perf_ratio*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee8e20-e2c7-49a2-9c40-d7384b49c4a7",
   "metadata": {},
   "source": [
    "## Create the machine learning pipeline and train for n epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0659e4-0922-4dde-a2d9-8b995ace620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the machine learning pipeline object here.\n",
    "# - It will want the control system object, the loss function, the optimizer for training.\n",
    "# Send this object to the device you want the training done.\n",
    "# Set training and validation data loaders for the pipeline.\n",
    "\n",
    "prob = Construct(cs, loss_fn, optimizer)\n",
    "prob.to(device)\n",
    "prob.set_loaders(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa3d76-1ef0-46e7-a062-1e07de75e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs for training and train for that many epochs.\n",
    "\n",
    "n_epochs = 10\n",
    "start_time = time.time()\n",
    "prob.capture_gradients(['controller.fcl.0', 'controller.fcl.1', 'controller.fcl.2', \n",
    "                        'controller.fcl.3'])\n",
    "prob.train(n_epochs)\n",
    "prob.remove_hooks()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d1228-2fc5-4502-89c0-769e906a5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in cs.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fb40d-fa4b-48db-a4fa-3ee3d4587885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell acquires the gradients during training for observation.\n",
    "# Choose which gradient you want to observe here for your report.\n",
    "# Discuss the behavior of the gradients with respect to the convergence of your model.\n",
    "\n",
    "gradients0 = np.array(prob._gradients['controller.fcl.0']['weight']).squeeze()\n",
    "print(gradients0.shape)\n",
    "gradients = gradients0[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85955a22-2432-4814-ba97-72c8a46fb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell normalizes and smooths out the gradients captured during training.\n",
    "\n",
    "corrected_gradients = calc_corrected_ewma(gradients, 19)\n",
    "corrected_sq_gradients = calc_corrected_ewma(np.power(gradients, 2), 1999)\n",
    "adapted_gradients = corrected_gradients / (np.sqrt(corrected_sq_gradients) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663a4fb-86d8-4ab6-8fb0-2097cddb8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell plots the gradients that are selected from the captured gradients.\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(15, 5))\n",
    "axs.plot(adapted_gradients[:-300], c='g', label='Adapted Gradients')\n",
    "axs.set_title('Gradients')\n",
    "axs.set_ylabel('Gradient')\n",
    "axs.set_xlabel('Mini-batches')\n",
    "axs.set_ylim([-1.5, 1.5])\n",
    "axs.legend(fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf83e2-5c00-437f-976c-449da1fdb3e4",
   "metadata": {},
   "source": [
    "## Verify that the training yields a good controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece26e1-4b7e-49bb-a30d-9b777ea31cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reperform the performance comparison between the neural net controller and LQR.\n",
    "# Simulate 30 trajectories starting from the same initial condition (selected randomly)\n",
    "# with the neural net controller and the linear quadratic regulator.\n",
    "# Compute the performance of each controller and print the average performance ratio\n",
    "# defined as neural net performance / lqr performance.\n",
    "\n",
    "perf_ratio = 0\n",
    "for k in range(30):\n",
    "    torch.manual_seed(50)\n",
    "    s0 = cs.robot.random_state()\n",
    "    traj_learned, ctrl_learned = cs.robot.simulate(controller=cs.controller, s0=s0)\n",
    "    traj_lqr, ctrl_lqr = cs.robot.simulate(controller=c, s0=s0)\n",
    "    cur_ratio = cs.loss_fn(traj_learned, ctrl_learned).item()/cs.loss_fn(traj_lqr, ctrl_lqr).item()\n",
    "    perf_ratio = perf_ratio + cur_ratio\n",
    "print(\"--- After training ---\")    \n",
    "print(f\"Performance ratio: {perf_ratio*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d5065-e020-4647-9e4b-33aa4ddface2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a couple of sample trajectories starting from a random initial state\n",
    "# One of these trajectories will be controller by the neural net, the other by LQR\n",
    "# Plot the time evolution of these trajectories (x and theta) w.r.t. time on the same plots for easy comparison.\n",
    "# Make the lqr trajectory dashdotted and the neural net solid.\n",
    "# Also provide a plot of the used control authority, both from the lqr and the neural net.\n",
    "\n",
    "s0 = cs.robot.random_state()\n",
    "traj_learned, ctrl_learned = cs.robot.simulate(controller=cs.controller, s0=s0)\n",
    "traj_lqr, ctrl_lqr = cs.robot.simulate(controller=c, s0=s0)\n",
    "\n",
    "x_learned, theta_learned = traj_learned[:, 0].detach().numpy(), traj_learned[:, 1].detach().numpy()\n",
    "x_lqr, theta_lqr = traj_lqr[:, 0].detach().numpy(), traj_lqr[:, 1].detach().numpy()\n",
    "\n",
    "\n",
    "time_1 = np.linspace(0, len(x_learned) * cs.robot.delta_t, len(x_learned))\n",
    "time_2 = np.linspace(0, len(x_lqr) * cs.robot.delta_t, len(x_lqr))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,8))\n",
    "axs[0].plot(time_1,x_learned,label='Neural Net')\n",
    "axs[0].plot(time_2,x_lqr,'r--',label='lqr')\n",
    "axs[0].set_title(\"Time evolution of the x - trajectories\", fontsize = 15)\n",
    "axs[0].set_xlabel('Time',fontsize = 10)\n",
    "axs[0].set_ylabel('x',fontsize = 10)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(time_1,theta_learned,label='Neural Net')\n",
    "axs[1].plot(time_2,theta_lqr,'r--',label='lqr')\n",
    "axs[1].set_title(\"Time evolution of the theta - trajectories\", fontsize = 15)\n",
    "axs[1].set_xlabel('Time',fontsize = 10)\n",
    "axs[1].set_ylabel('theta',fontsize = 10)\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c8ec5-ffee-4566-a9ae-e75db1e6265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig  = plt.figure(figsize=(8,5))\n",
    "plt.plot(time_1,ctrl_learned.detach().numpy(),label='Neural Net')\n",
    "plt.plot(time_2,ctrl_lqr.detach().numpy(),'r--',label='lqr')\n",
    "plt.title(\"Plot of the Used Control Authority\", fontsize = 15)\n",
    "plt.xlabel('Time',fontsize = 10)\n",
    "plt.ylabel('Control authority',fontsize = 10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba2d5c-c74d-47a0-8cfd-b103aac612bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plots training losses obtained during training and then the validation \n",
    "# losses on the same plot. \n",
    "# Interpret these plots in your report.\n",
    "\n",
    "prob.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb585a6d-1ecd-4cba-875f-1929658e3a19",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b972c-191f-4353-b4df-2923f64cc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 1000\n",
    "total_loss_lqr = 0\n",
    "total_loss_nn = 0\n",
    "for _ in range(num_simulations):\n",
    "    torch.manual_seed(50)\n",
    "    s0 = cs.robot.random_state()\n",
    "    traj_learned, ctrl_learned = cs.robot.simulate(controller=cs.controller, s0=s0)\n",
    "    traj_lqr, ctrl_lqr = cs.robot.simulate(controller=c, s0=s0)\n",
    "\n",
    "    # Compute loss for neural network controller\n",
    "    for i in range(len(traj_learned)):\n",
    "        x, theta, x_dot, theta_dot = traj_learned[i]\n",
    "        f = ctrl_learned[i]\n",
    "        total_loss_nn += loss_fn\n",
    "\n",
    "    # Compute loss for LQR controller\n",
    "    for i in range(len(traj_lqr)):\n",
    "        x, theta, x_dot, theta_dot = traj_lqr[i]\n",
    "        f = ctrl_lqr[i]\n",
    "        total_loss_lqr += loss_fn\n",
    "\n",
    "# Calculate average loss\n",
    "average_loss_nn = total_loss_nn / num_simulations\n",
    "average_loss_lqr = total_loss_lqr / num_simulations\n",
    "\n",
    "# Compare performance\n",
    "print(f\"Average Loss - Neural Network: {average_loss_nn}\")\n",
    "print(f\"Average Loss - LQR: {average_loss_lqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81032b5d-d663-4f5e-b436-ef995ab29428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
